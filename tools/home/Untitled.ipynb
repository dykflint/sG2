{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeaf4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e9b76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n",
      "Num GPUs Available:  1\n",
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /Users/konstantin/tensorflow_datasets/mnist/3.0.1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67d2afcdfc246289a110df90cbcf19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mnist downloaded and prepared to /Users/konstantin/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x1785a1ee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x1785a1ee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x1785a1ee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x1785a1ee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function normalize_img at 0x1785a1ee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function normalize_img at 0x1785a1ee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-4-ff30964a0426>\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', 'import tensorflow as tf\\nimport tensorflow_datasets as tfds\\nprint(\"TensorFlow version:\", tf.__version__)\\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices(\\'GPU\\')))\\ntf.config.list_physical_devices(\\'GPU\\')\\n(ds_train, ds_test), ds_info = tfds.load(\\n    \\'mnist\\',\\n    split=[\\'train\\', \\'test\\'],\\n    shuffle_files=True,\\n    as_supervised=True,\\n    with_info=True,\\n)\\ndef normalize_img(image, label):\\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\\n  return tf.cast(image, tf.float32) / 255., label\\nbatch_size = 128\\nds_train = ds_train.map(\\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\nds_train = ds_train.cache()\\nds_train = ds_train.shuffle(ds_info.splits[\\'train\\'].num_examples)\\nds_train = ds_train.batch(batch_size)\\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\\nds_test = ds_test.map(\\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\nds_test = ds_test.batch(batch_size)\\nds_test = ds_test.cache()\\nds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\\nmodel = tf.keras.models.Sequential([\\n  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\\n                 activation=\\'relu\\'),\\n  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\\n                 activation=\\'relu\\'),\\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\\n#   tf.keras.layers.Dropout(0.25),\\n  tf.keras.layers.Flatten(),\\n  tf.keras.layers.Dense(128, activation=\\'relu\\'),\\n#   tf.keras.layers.Dropout(0.5),\\n  tf.keras.layers.Dense(10, activation=\\'softmax\\')\\n])\\nmodel.compile(\\n    loss=\\'sparse_categorical_crossentropy\\',\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n    metrics=[\\'accuracy\\'],\\n)\\nmodel.fit(\\n    ds_train,\\n    epochs=12,\\n    validation_data=ds_test,\\n)\\n')\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2430, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/magics/execution.py\", line 1324, in time\n      out = eval(code_2, glob, local_ns)\n    File \"<timed exec>\", line 45, in <module>\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\ncould not find registered platform with id: 0x103cc67d0\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_1265]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:45\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/mambaforge/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-4-ff30964a0426>\", line 1, in <module>\n      get_ipython().run_cell_magic('time', '', 'import tensorflow as tf\\nimport tensorflow_datasets as tfds\\nprint(\"TensorFlow version:\", tf.__version__)\\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices(\\'GPU\\')))\\ntf.config.list_physical_devices(\\'GPU\\')\\n(ds_train, ds_test), ds_info = tfds.load(\\n    \\'mnist\\',\\n    split=[\\'train\\', \\'test\\'],\\n    shuffle_files=True,\\n    as_supervised=True,\\n    with_info=True,\\n)\\ndef normalize_img(image, label):\\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\\n  return tf.cast(image, tf.float32) / 255., label\\nbatch_size = 128\\nds_train = ds_train.map(\\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\nds_train = ds_train.cache()\\nds_train = ds_train.shuffle(ds_info.splits[\\'train\\'].num_examples)\\nds_train = ds_train.batch(batch_size)\\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\\nds_test = ds_test.map(\\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\nds_test = ds_test.batch(batch_size)\\nds_test = ds_test.cache()\\nds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\\nmodel = tf.keras.models.Sequential([\\n  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\\n                 activation=\\'relu\\'),\\n  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\\n                 activation=\\'relu\\'),\\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\\n#   tf.keras.layers.Dropout(0.25),\\n  tf.keras.layers.Flatten(),\\n  tf.keras.layers.Dense(128, activation=\\'relu\\'),\\n#   tf.keras.layers.Dropout(0.5),\\n  tf.keras.layers.Dense(10, activation=\\'softmax\\')\\n])\\nmodel.compile(\\n    loss=\\'sparse_categorical_crossentropy\\',\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n    metrics=[\\'accuracy\\'],\\n)\\nmodel.fit(\\n    ds_train,\\n    epochs=12,\\n    validation_data=ds_test,\\n)\\n')\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2430, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/IPython/core/magics/execution.py\", line 1324, in time\n      out = eval(code_2, glob, local_ns)\n    File \"<timed exec>\", line 45, in <module>\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/konstantin/mambaforge/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\ncould not find registered platform with id: 0x103cc67d0\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_1265]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "batch_size = 128\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750ea61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
